{"cells":[{"cell_type":"code","execution_count":1,"id":"36243979","metadata":{"id":"36243979","executionInfo":{"status":"ok","timestamp":1745342500153,"user_tz":240,"elapsed":8870,"user":{"displayName":"Joshua Maupin","userId":"06550489812925885821"}}},"outputs":[],"source":["import cv2\n","import os\n","\n","import torch\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from glob import glob\n","\n","import matplotlib.pyplot as plt\n","\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torchvision import transforms\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.checkpoint import checkpoint"]},{"cell_type":"code","source":["#Connect to drive:\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BEKNv9RgeRdl","executionInfo":{"status":"ok","timestamp":1745342500704,"user_tz":240,"elapsed":548,"user":{"displayName":"Joshua Maupin","userId":"06550489812925885821"}},"outputId":"86b996d4-ef15-4e14-fd6e-8b541af7a51d"},"id":"BEKNv9RgeRdl","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/COSC 424 Files/Unet V2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vcC4QveNeUE2","executionInfo":{"status":"ok","timestamp":1745342500713,"user_tz":240,"elapsed":7,"user":{"displayName":"Joshua Maupin","userId":"06550489812925885821"}},"outputId":"c8834651-83c8-4991-a42e-b674251f7b92"},"id":"vcC4QveNeUE2","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1hJIjUR_EcP2-fL1FsABfrKHiW4AkMw9y/COSC 424 Files/Unet V2\n"]}]},{"cell_type":"code","execution_count":4,"id":"1b834bed","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1b834bed","executionInfo":{"status":"ok","timestamp":1745342500722,"user_tz":240,"elapsed":8,"user":{"displayName":"Joshua Maupin","userId":"06550489812925885821"}},"outputId":"0732d25d-33dd-49a7-d207-3a75ecb1c17e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":5,"id":"dfd270e8","metadata":{"id":"dfd270e8","executionInfo":{"status":"ok","timestamp":1745342500727,"user_tz":240,"elapsed":4,"user":{"displayName":"Joshua Maupin","userId":"06550489812925885821"}}},"outputs":[],"source":["def display_image_with_mask(image: torch.tensor, mask: np.ndarray, alpha: float = 0.5):\n","    \"\"\"\n","    Display a grayscale image with a binary mask overlaid.\n","\n","    Parameters:\n","    - image: 2D tensor for a scan\n","    - mask:  2D numpy array of same shape with binary values (0 or 1).\n","    - alpha: float transparency for mask overlay.\n","    \"\"\"\n","    plt.figure()\n","    plt.imshow(image, cmap='gray')\n","    plt.imshow(mask, alpha=alpha)\n","    plt.axis('off')\n","    plt.show()"]},{"cell_type":"code","execution_count":6,"id":"20a89375","metadata":{"id":"20a89375","executionInfo":{"status":"ok","timestamp":1745342500752,"user_tz":240,"elapsed":13,"user":{"displayName":"Joshua Maupin","userId":"06550489812925885821"}}},"outputs":[],"source":["# This class stores a scan slice image and its associated mask\n","class ScanSlice:\n","    def __init__(self, file_path, shape, transform=None):\n","        self.file_path = file_path\n","        self.transform = transform\n","        self.shape = shape\n","\n","        # format the file name properly\n","        case_path = file_path.split('/')\n","        slice_name = case_path[-1].split('_')\n","\n","        # name is the name in the train.csv file\n","        # original shape is the shape of the raw image before transform\n","        self.name = f\"{case_path[-3]}_slice_{slice_name[1]}\"\n","        self.original_shape = (int(slice_name[2]), int(slice_name[3]))\n","\n","        # apply a default mask\n","        self.mask = np.zeros(self.shape, dtype=np.uint8)\n","        self.masks = {\"stomach\": np.zeros(self.shape, dtype=np.uint8),\n","                      \"small_bowel\": np.zeros(self.shape, dtype=np.uint8),\n","                      \"large_bowel\": np.zeros(self.shape, dtype=np.uint8)}\n","\n","        # init the mask values that we will use\n","        self.mask_values = {\"large_bowel\": 1, \"small_bowel\": 2, \"stomach\": 3}\n","\n","    def features(self, device=\"cpu\", dtype=torch.float):\n","        # load image into memory\n","        img_data = cv2.imread(self.file_path, cv2.IMREAD_UNCHANGED)\n","\n","        # format the data accordingly\n","        result = self.transform(img_data)\n","        result = result.to(dtype=dtype)\n","        result.to(device)\n","\n","        return result\n","\n","    def decode_rle(self, rle, label):\n","        # make sure the rle is not empty\n","        if not rle or (type(rle) is not str and np.isnan(rle)) or rle.strip() == \"\":\n","            self.mask = np.zeros(self.shape, dtype=np.uint8)\n","            return\n","\n","        s = list(map(int, rle.strip().split()))\n","        starts, lengths = s[::2], s[1::2]\n","        starts = np.array(starts)\n","        ends = starts + lengths\n","\n","        mask = np.zeros(self.original_shape[0] * self.original_shape[1], dtype=np.uint8)\n","        for start, end in zip(starts, ends):\n","            mask[start:end] = 1\n","\n","        mask = cv2.resize(mask.reshape(self.original_shape), self.shape, interpolation=cv2.INTER_NEAREST)\n","        self.masks[label] = mask\n","\n","        self.mask[mask == 1] = self.mask_values[label]\n","\n","        allowed = {0, 1, 2, 3}\n","        unique_vals = np.unique(mask)\n","\n","        if not set(unique_vals).issubset(allowed):\n","            raise Exception(\"An invalid value was found in a sample mask\")\n","\n","\n","class MRIData(Dataset):\n","    def __init__(self, transform, slice_shape, device=\"cpu\"):\n","        self.slices = dict()\n","        self.slice_index = list()\n","\n","        self.device = device\n","        self.transform = transform\n","        self.slice_shape = slice_shape\n","\n","        self.read_slice_data()\n","        self.read_rles()\n","\n","    def __getitem__(self, idx):\n","        if type(idx) == str:\n","            return self.slices[idx].features(device=self.device), self.slices[idx].mask.astype(np.int64)\n","        return self.slice_index[idx].features(device=self.device), self.slice_index[idx].mask.astype(np.int64)\n","\n","    def __len__(self):\n","        return len(self.slices)\n","\n","    def get_slice(self, idx):\n","        if type(idx) == str:\n","            return self.slices[idx]\n","        return self.slice_index[idx]\n","\n","    def read_slice_data(self):\n","        # get all of the slice paths\n","        slices = glob(f\"{os.getcwd()}/gi-tract-data/train/*/*/scans/slice_*\")\n","        slices = [slice.replace(\"\\\\\", \"/\") for slice in slices]\n","\n","        # create a slice object for every slice\n","        for slice_path in slices:\n","            ss = ScanSlice(slice_path, self.slice_shape, self.transform)\n","            self.slice_index.append(ss)\n","            self.slices[ss.name] = ss\n","\n","    def read_rles(self):\n","        # open the train.csv file\n","        train_csv_path = f\"{os.getcwd()}/gi-tract-data/train.csv\"\n","        rle_file = pd.read_csv(train_csv_path)\n","\n","        # give each slice its rle\n","        for i in range(0, len(rle_file)):\n","            slice_name, label, rle = rle_file.iloc[i]\n","            self.slices[slice_name].decode_rle(rle, label)"]},{"cell_type":"code","execution_count":null,"id":"66b6e55e","metadata":{"id":"66b6e55e"},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((256, 256))\n","])\n","\n","mrid = MRIData(transform, (256, 256), device=device)\n","training_data = Subset(mrid, list(range(3000)))\n","train_loader= DataLoader(training_data, batch_size=16, shuffle=True)"]},{"cell_type":"code","execution_count":null,"id":"b0736a34","metadata":{"id":"b0736a34"},"outputs":[],"source":["class DiceLoss(nn.Module):\n","    \"\"\"\n","    Multi‑class Dice loss.\n","    Expects:\n","      - logits: (B, C, H, W) raw network outputs\n","      - targets: (B, H, W) integer class labels in [0..C-1]\n","    \"\"\"\n","    def __init__(self, smooth: float = 1e-5):\n","        super().__init__()\n","        self.smooth = smooth\n","\n","    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n","        # Number of classes from logits shape\n","        num_classes = logits.shape[1]\n","\n","        # Convert to probabilities\n","        probs = F.softmax(logits, dim=1)\n","\n","        # One‑hot encode targets to shape (B, C, H, W)\n","        with torch.no_grad():\n","            targets_one_hot = F.one_hot(targets, num_classes)  # (B, H, W, C)\n","            targets_one_hot = targets_one_hot.permute(0, 3, 1, 2).float()\n","\n","        # Compute per‑class Dice score\n","        dims = (0, 2, 3)  # sum over batch & spatial dims\n","        intersection = torch.sum(probs * targets_one_hot, dims)\n","        cardinality  = torch.sum(probs + targets_one_hot, dims)\n","        dice_score   = (2. * intersection + self.smooth) / (cardinality + self.smooth)\n","\n","        # Dice loss is 1 – mean Dice score across classes\n","        return 1. - dice_score.mean()\n","\n","class CombinedLoss(nn.Module):\n","    \"\"\"\n","    α * CrossEntropy + (1-α) * DiceLoss\n","    \"\"\"\n","    def __init__(self, alpha: float = 0.5, weight: torch.Tensor = None, ignore_index: int = -100):\n","        \"\"\"\n","        Args:\n","          alpha       – weight for the CrossEntropy term (in [0,1])\n","          weight      – optional tensor of shape (C,) to weight classes in CE\n","          ignore_index– optional index to ignore in CE and Dice\n","        \"\"\"\n","        super().__init__()\n","        self.alpha = alpha\n","        self.ce    = nn.CrossEntropyLoss(weight=weight, ignore_index=ignore_index)\n","        self.dice  = DiceLoss()\n","\n","    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        logits: (B, C, H, W)\n","        targets: (B, H, W)\n","        \"\"\"\n","        loss_ce   = self.ce(logits, targets)\n","        loss_dice = self.dice(logits, targets)\n","        return self.alpha * loss_ce + (1. - self.alpha) * loss_dice"]},{"cell_type":"code","execution_count":null,"id":"e7855589","metadata":{"id":"e7855589"},"outputs":[],"source":["# Define a double convolution block: (Conv -> BatchNorm -> ReLU) * 2\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DoubleConv, self).__init__()\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","# Downsampling block: MaxPool then DoubleConv\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(Down, self).__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","class BottleneckResBlock(nn.Module):\n","    def __init__(self, in_channels, dropout_prob=0.3):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(in_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout2d(p=dropout_prob),\n","            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(in_channels)\n","        )\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        return self.relu(x + self.conv(x))\n","\n","# Upsampling block: Upsample (or ConvTranspose2d) then DoubleConv.\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(Up, self).__init__()\n","        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        # x1 is from the previous layer (decoder), x2 is from the encoder (skip connection)\n","        x1 = self.up(x1)\n","        # pad x1 if necessary to match dimensions of x2\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                        diffY // 2, diffY - diffY // 2])\n","        # concatenate along the channel dimension\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","# Final output convolution to reduce the number of channels to the desired number of classes.\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)"]},{"cell_type":"code","execution_count":null,"id":"cc434add","metadata":{"id":"cc434add"},"outputs":[],"source":["# this reduces memory problems with cuda\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"id":"45f3373c","metadata":{"id":"45f3373c"},"outputs":[],"source":["# Define the U-Net architecture\n","class UNet(nn.Module):\n","    def __init__(self, n_channels, n_classes):\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","\n","        self.inc = DoubleConv(n_channels, 64)\n","        self.down1 = Down(64, 128)\n","        self.down2 = Down(128, 256)\n","        self.down3 = Down(256, 512)\n","        self.down4 = Down(512, 1024)\n","        self.bottleneck = BottleneckResBlock(1024)\n","        self.up1 = Up(1024, 512)\n","        self.up2 = Up(512, 256)\n","        self.up3 = Up(256, 128)\n","        self.up4 = Up(128, 64)\n","        self.outc = OutConv(64, n_classes)\n","\n","    def forward(self, x):\n","        # Encoder path\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        x5 = self.bottleneck(x5)\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","        logits = self.outc(x)\n","        return logits"]},{"cell_type":"code","execution_count":null,"id":"3904b24a","metadata":{"id":"3904b24a"},"outputs":[],"source":["# monochrome => n_channels=1, three class + background => n_classes=4\n","model = UNet(n_channels=1, n_classes=4)\n","model.to(device)\n","\n","pos_weight = torch.tensor([5.0], device=device)\n","criterion = CombinedLoss(alpha=0.3)\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)"]},{"cell_type":"code","execution_count":null,"id":"a9f03b95","metadata":{"id":"a9f03b95"},"outputs":[],"source":["num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","    model.train()  # Set the model to training mode.\n","    train_loss = 0.0\n","\n","    for inputs, targets in train_loader:\n","        print(inputs.size())\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","\n","        # Move the data to the proper device.\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","\n","        # do the training stuff\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Accumulate the loss for this batch.\n","        train_loss += loss.item() * inputs.size(0)\n","\n","    # Compute average training loss.\n","    train_loss /= len(train_loader.dataset)\n","    print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {train_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"id":"1b5cedcc","metadata":{"id":"1b5cedcc"},"outputs":[],"source":["# save the model\n","torch.save(model.state_dict(), 'model_1000_100_2_a.ai')"]},{"cell_type":"code","execution_count":null,"id":"6e1b4815","metadata":{"id":"6e1b4815"},"outputs":[],"source":["# load the model\n","model = UNet(n_channels=1, n_classes=4)\n","model.load_state_dict(torch.load('model_1000_100_2.ai'))\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"id":"04c6f1f0","metadata":{"id":"04c6f1f0"},"outputs":[],"source":["# errors with: case133_day25_slice_0049, All of day 77\n","X, y = mrid[\"case139_day0_slice_0062\"]\n","y[y != 0] = 1\n","\n","display_image_with_mask(X.squeeze(), y)\n","\n","X_pred = X.unsqueeze(0).to(device)\n","y_pred = model(X_pred)\n","\n","y_pred = torch.argmax(y_pred, dim=1)\n","y_pred[y_pred != 0] = 1\n","\n","y_print = y_pred.detach().cpu().numpy()\n","display_image_with_mask(X.squeeze(), y_print.squeeze())"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}