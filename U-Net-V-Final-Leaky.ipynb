{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36243979",
   "metadata": {
    "id": "36243979"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Sampler\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e887970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_epochs = (200, 0, 100)\n",
    "dataset_sample_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b834bed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1745327062586,
     "user": {
      "displayName": "James Shastid",
      "userId": "17989604286405767232"
     },
     "user_tz": 240
    },
    "id": "1b834bed",
    "outputId": "feaad031-d273-4ba4-c48b-e2e1a9c12aeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a89375",
   "metadata": {
    "id": "20a89375"
   },
   "outputs": [],
   "source": [
    "# This class stores a scan slice image and its associated mask\n",
    "class ScanSlice:\n",
    "    def __init__(self, file_path, shape, transform=None):\n",
    "        self.file_path = file_path\n",
    "        self.transform = transform\n",
    "        self.shape = shape\n",
    "        self.feature_data = None\n",
    "        self.mask_count = 0\n",
    "\n",
    "        # format the file name properly\n",
    "        case_path = file_path.split('/')\n",
    "        slice_name = case_path[-1].split('_')\n",
    "\n",
    "        # name is the name in the train.csv file\n",
    "        # original shape is the shape of the raw image before transform\n",
    "        self.name = f\"{case_path[-3]}_slice_{slice_name[1]}\"\n",
    "        self.original_shape = (int(slice_name[3]), int(slice_name[2]))\n",
    "\n",
    "        # apply a default mask\n",
    "        self.mask = np.zeros(self.shape, dtype=np.uint8)\n",
    "\n",
    "        # init the mask values that we will use\n",
    "        self.mask_values = {\"large_bowel\": 1, \"small_bowel\": 2, \"stomach\": 3}\n",
    "\n",
    "    def features(self, device=\"cpu\", dtype=torch.float):\n",
    "        return self.feature_data\n",
    "\n",
    "    def decode_rle(self, rle, label):\n",
    "        # make sure the rle is not empty\n",
    "        if not rle or (type(rle) is not str and np.isnan(rle)) or rle.strip() == \"\":\n",
    "            return\n",
    "\n",
    "        self.mask_count += 1\n",
    "        s = list(map(int, rle.strip().split()))\n",
    "        starts, lengths = s[::2], s[1::2]\n",
    "        starts = np.array(starts)\n",
    "        ends = starts + lengths\n",
    "\n",
    "        mask = np.zeros(self.original_shape[0] * self.original_shape[1], dtype=np.uint8)\n",
    "        for start, end in zip(starts, ends):\n",
    "            mask[start:end] = 1\n",
    "\n",
    "        mask = cv2.resize(mask.reshape(self.original_shape), self.shape, interpolation=cv2.INTER_NEAREST)\n",
    "        self.mask[mask == 1] = self.mask_values[label]\n",
    "\n",
    "    def load_slice(self, device=\"cpu\", dtype=torch.float):\n",
    "                # load image into memory\n",
    "        img_data = cv2.imread(self.file_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        # format the data accordingly\n",
    "        result = self.transform(img_data)\n",
    "        result = result.to(dtype=dtype)\n",
    "        result.to(device)\n",
    "        self.feature_data = result\n",
    "        \n",
    "\n",
    "\n",
    "class MRIData(Dataset):\n",
    "    def __init__(self, transform, slice_shape, device=\"cpu\"):\n",
    "        self.slices = dict()\n",
    "        self.slice_index = list()\n",
    "\n",
    "        self.device = device\n",
    "        self.transform = transform\n",
    "        self.slice_shape = slice_shape\n",
    "\n",
    "        self.full = list()\n",
    "        self.mixed = list()\n",
    "        self.empty = list()\n",
    "\n",
    "        self.read_slice_data()\n",
    "        self.read_rles()\n",
    "\n",
    "        n_samples = int(len(self.slice_index) * dataset_sample_size)\n",
    "        self.slice_index = self.slice_index[:n_samples]\n",
    "\n",
    "        self.slices = dict()\n",
    "        for sample in self.slice_index:\n",
    "            self.slices[sample.name] = sample\n",
    "\n",
    "        self.sort_samples()\n",
    "        for sample in self.slice_index:\n",
    "            sample.load_slice()\n",
    "\n",
    "        print(f\"full samples: {len(self.full)}\")\n",
    "        print(f\"mixed samples: {len(self.mixed)}\")\n",
    "        print(f\"empty samples: {len(self.empty)}\")\n",
    "        \n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if type(idx) == str:\n",
    "            return self.slices[idx].features(device=self.device), self.slices[idx].mask.astype(np.int64)\n",
    "        return self.slice_index[idx].features(device=self.device), self.slice_index[idx].mask.astype(np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices)\n",
    "\n",
    "    def get_slice(self, idx):\n",
    "        if type(idx) == str:\n",
    "            return self.slices[idx]\n",
    "        return self.slice_index[idx]\n",
    "\n",
    "    def read_slice_data(self):\n",
    "        # get all of the slice paths\n",
    "        slices = glob(f\"{os.getcwd()}/gi-tract-data/train/*/*/scans/slice_*\")\n",
    "        slices = [slice.replace(\"\\\\\", \"/\") for slice in slices]\n",
    "\n",
    "        # create a slice object for every slice\n",
    "        for slice_path in slices:\n",
    "            ss = ScanSlice(slice_path, self.slice_shape, self.transform)\n",
    "            self.slice_index.append(ss)\n",
    "            self.slices[ss.name] = ss\n",
    "\n",
    "    def read_rles(self):\n",
    "        # open the train.csv file\n",
    "        train_csv_path = f\"{os.getcwd()}/gi-tract-data/train.csv\"\n",
    "        rle_file = pd.read_csv(train_csv_path)\n",
    "\n",
    "        # give each slice its rle\n",
    "        for i in range(0, len(rle_file)):\n",
    "            slice_name, label, rle = rle_file.iloc[i]\n",
    "            self.slices[slice_name].decode_rle(rle, label)\n",
    "\n",
    "    def sort_samples(self):\n",
    "        for i in range(len(self.slices)):\n",
    "            sample = self.get_slice(i)\n",
    "            if sample.mask_count == 0:\n",
    "                self.empty.append(i)\n",
    "            elif sample.mask_count == 3:\n",
    "                self.full.append(i)\n",
    "            else:\n",
    "                self.mixed.append(i)\n",
    "\n",
    "    def display_image_with_mask(self, idx):\n",
    "        img, mask = self[idx]\n",
    "        plt.figure()\n",
    "        plt.imshow(img.squeeze(), cmap='gray')\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37422f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler(Sampler):\n",
    "    def __init__(self, train_dataset, full, mixed, empty, batch_size, full_count, mixed_count, empty_count):\n",
    "        self.full = full\n",
    "        self.mixed = mixed\n",
    "        self.none = empty\n",
    "        self.batch_size = batch_size\n",
    "        self.full_count = full_count\n",
    "        self.partial_count = mixed_count\n",
    "        self.none_count = empty_count\n",
    "        self.dataset_len = len(train_dataset)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch = (\n",
    "            random.sample(self.full, self.full_count) +\n",
    "            random.sample(self.mixed, self.partial_count) +\n",
    "            random.sample(self.none, self.none_count)\n",
    "        )\n",
    "        random.shuffle(batch)\n",
    "        yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b6e55e",
   "metadata": {
    "id": "66b6e55e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full samples: 334\n",
      "mixed samples: 1403\n",
      "empty samples: 2112\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256))\n",
    "])\n",
    "\n",
    "mrid = MRIData(transform, (256, 256), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f3b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(indices, train_ratio=0.8, val_ratio=0.10, test_ratio=0.10, seed=42):\n",
    "    train, temp = train_test_split(indices, test_size=(1 - train_ratio), random_state=seed)\n",
    "    val, test = train_test_split(temp, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=seed)\n",
    "    return train, val, test\n",
    "\n",
    "full_train, full_val, full_test = split_indices(mrid.full)\n",
    "partial_train, partial_val, partial_test = split_indices(mrid.mixed)\n",
    "if len(mrid.empty) > 0:\n",
    "    none_train, none_val, none_test = split_indices(mrid.empty)\n",
    "else:\n",
    "    none_train, none_val, none_test = [], [], []\n",
    "train_indices = full_train + partial_train + none_train\n",
    "val_indices = full_val + partial_val + none_val\n",
    "test_indices = full_test + partial_test + none_test\n",
    "\n",
    "train_dataset = Subset(mrid, train_indices)\n",
    "val_dataset = Subset(mrid, val_indices)\n",
    "test_dataset = Subset(mrid, test_indices)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "def get_train_loader_ratio(train_dataset, full_count, mixed_count, empty_count):\n",
    "    full = list()\n",
    "    mixed = list()\n",
    "    empty = list()\n",
    "\n",
    "    for i in range(len(train_indices)):\n",
    "        if mrid.get_slice(train_indices[i]).mask_count == 3:\n",
    "            full.append(i)\n",
    "        elif mrid.get_slice(train_indices[i]).mask_count == 0:\n",
    "            empty.append(i)\n",
    "        else:\n",
    "            mixed.append(i)\n",
    "\n",
    "    sampler = BatchSampler(\n",
    "    train_dataset=train_dataset,\n",
    "    full=full,\n",
    "    mixed=mixed,\n",
    "    empty=empty,\n",
    "    batch_size=16,\n",
    "    full_count=full_count,\n",
    "    mixed_count=mixed_count,\n",
    "    empty_count=empty_count\n",
    "    )\n",
    "    return DataLoader(train_dataset, batch_sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0736a34",
   "metadata": {
    "id": "b0736a34"
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi‑class Dice loss.\n",
    "    Expects:\n",
    "      - logits: (B, C, H, W) raw network outputs\n",
    "      - targets: (B, H, W) integer class labels in [0..C-1]\n",
    "    \"\"\"\n",
    "    def __init__(self, smooth: float = 1e-5):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        # Number of classes from logits shape\n",
    "        num_classes = logits.shape[1]\n",
    "\n",
    "        # Convert to probabilities\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        # One‑hot encode targets to shape (B, C, H, W)\n",
    "        with torch.no_grad():\n",
    "            targets_one_hot = F.one_hot(targets, num_classes)  # (B, H, W, C)\n",
    "            targets_one_hot = targets_one_hot.permute(0, 3, 1, 2).float()\n",
    "\n",
    "        # Compute per‑class Dice score\n",
    "        dims = (0, 2, 3)  # sum over batch & spatial dims\n",
    "        intersection = torch.sum(probs * targets_one_hot, dims)\n",
    "        cardinality  = torch.sum(probs + targets_one_hot, dims)\n",
    "        dice_score   = (2. * intersection + self.smooth) / (cardinality + self.smooth)\n",
    "\n",
    "        # Dice loss is 1 – mean Dice score across classes\n",
    "        return 1. - dice_score.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha: float = 0.5, weight: torch.Tensor = None, ignore_index: int = -100):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.ce    = nn.CrossEntropyLoss(weight=weight, ignore_index=ignore_index)\n",
    "        self.dice  = DiceLoss()\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        loss_ce   = self.ce(logits, targets)\n",
    "        loss_dice = self.dice(logits, targets)\n",
    "        return self.alpha * loss_ce + (1. - self.alpha) * loss_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7855589",
   "metadata": {
    "id": "e7855589"
   },
   "outputs": [],
   "source": [
    "# Define a double convolution block: (Conv -> BatchNorm -> ReLU) * 2\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "# Downsampling block: MaxPool then DoubleConv\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down, self).__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class BottleneckResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Dropout2d(p=dropout_prob),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(in_channels)\n",
    "        )\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + self.conv(x))\n",
    "\n",
    "# Upsampling block: Upsample (or ConvTranspose2d) then DoubleConv.\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Up, self).__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # x1 is from the previous layer (decoder), x2 is from the encoder (skip connection)\n",
    "        x1 = self.up(x1)\n",
    "        # pad x1 if necessary to match dimensions of x2\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # concatenate along the channel dimension\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "# Final output convolution to reduce the number of channels to the desired number of classes.\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc434add",
   "metadata": {
    "id": "cc434add"
   },
   "outputs": [],
   "source": [
    "# this reduces memory problems with cuda\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45f3373c",
   "metadata": {
    "id": "45f3373c"
   },
   "outputs": [],
   "source": [
    "# Define the U-Net architecture\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        self.bottleneck = BottleneckResBlock(1024)\n",
    "        self.up1 = Up(1536, 512)\n",
    "        self.up2 = Up(768, 256)\n",
    "        self.up3 = Up(384, 128)\n",
    "        self.up4 = Up(192, 64)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x5 = self.bottleneck(x5)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3904b24a",
   "metadata": {
    "id": "3904b24a"
   },
   "outputs": [],
   "source": [
    "model = UNet(n_channels=1, n_classes=4)\n",
    "model.to(device)\n",
    "\n",
    "criterion = CombinedLoss(alpha=0.05)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9741e67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13bf3bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([16, 1, 256, 256])\n",
      "Targets shape: torch.Size([16, 256, 256])\n",
      "Inputs dtype: torch.float32\n",
      "Targets dtype: torch.int64\n",
      "tensor([[[[   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          ...,\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.]]],\n",
      "\n",
      "\n",
      "        [[[   4.,   11.,    8.,  ...,    6.,    9.,   23.],\n",
      "          [   3.,    8.,    5.,  ...,    5.,    7.,   13.],\n",
      "          [   2.,    6.,    3.,  ...,    4.,    6.,    9.],\n",
      "          ...,\n",
      "          [ 292.,  791.,  658.,  ...,  369.,  440.,  542.],\n",
      "          [ 331.,  921.,  745.,  ...,  416.,  514.,  594.],\n",
      "          [ 369., 1047.,  869.,  ...,  466.,  554.,  611.]]],\n",
      "\n",
      "\n",
      "        [[[   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          ...,\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[   6.,   18.,   11.,  ...,  329.,  398.,  482.],\n",
      "          [   5.,   14.,    9.,  ...,  283.,  352.,  415.],\n",
      "          [   4.,   11.,    7.,  ...,  221.,  299.,  358.],\n",
      "          ...,\n",
      "          [ 207.,  580.,  481.,  ...,  343.,  317.,  496.],\n",
      "          [ 229.,  652.,  552.,  ...,  338.,  379.,  606.],\n",
      "          [ 252.,  718.,  619.,  ...,  310.,  554.,  689.]]],\n",
      "\n",
      "\n",
      "        [[[   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          ...,\n",
      "          [   0.,    0.,    2.,  ...,    0.,    0.,    0.],\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "          [   0.,    0.,    0.,  ...,    0.,    0.,    0.]]],\n",
      "\n",
      "\n",
      "        [[[   9.,   25.,   12.,  ...,   16.,   42.,  501.],\n",
      "          [   6.,   14.,   11.,  ...,   13.,   18.,   88.],\n",
      "          [   4.,   12.,   10.,  ...,    9.,   15.,   23.],\n",
      "          ...,\n",
      "          [ 426., 1198.,  981.,  ...,  547.,  668.,  801.],\n",
      "          [ 480., 1344., 1145.,  ...,  609.,  759.,  835.],\n",
      "          [ 530., 1512., 1279.,  ...,  695.,  808.,  701.]]]])\n",
      "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "#Get one set of inputs and targets from the train loader\n",
    "for inputs, targets in val_loader:\n",
    "    print(f\"Inputs shape: {inputs.shape}\")\n",
    "    print(f\"Targets shape: {targets.shape}\")\n",
    "    print(f\"Inputs dtype: {inputs.dtype}\")\n",
    "    print(f\"Targets dtype: {targets.dtype}\")\n",
    "    print(inputs)\n",
    "    print(targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d66039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    for inputs, targets in val_loader:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        val_loss.append(loss.detach())\n",
    "\n",
    "    batch_losses = torch.stack(val_loss).mean().item()   \n",
    "    return {'val_loss': batch_losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9f03b95",
   "metadata": {
    "id": "a9f03b95",
    "outputId": "74b1d02a-7f3d-4df0-c593-ff83f41d09df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_6012\\2459447256.py:31: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Scalar.cpp:23.)\n",
      "  train_loss += loss.item() * inputs.size(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 - Train Loss: 0.9012 - Val Loss: 0.9279\n",
      "Epoch 2/200 - Train Loss: 0.8883 - Val Loss: 0.9264\n",
      "Epoch 3/200 - Train Loss: 0.8699 - Val Loss: 0.9244\n",
      "Epoch 4/200 - Train Loss: 0.8745 - Val Loss: 0.9226\n",
      "Epoch 5/200 - Train Loss: 0.8537 - Val Loss: 0.9202\n",
      "Epoch 6/200 - Train Loss: 0.8463 - Val Loss: 0.9171\n",
      "Epoch 7/200 - Train Loss: 0.8468 - Val Loss: 0.9142\n",
      "Epoch 8/200 - Train Loss: 0.8360 - Val Loss: 0.9105\n",
      "Epoch 9/200 - Train Loss: 0.8232 - Val Loss: 0.9061\n",
      "Epoch 10/200 - Train Loss: 0.8124 - Val Loss: 0.9012\n",
      "Epoch 11/200 - Train Loss: 0.8158 - Val Loss: 0.8964\n",
      "Epoch 12/200 - Train Loss: 0.8193 - Val Loss: 0.8922\n",
      "Epoch 13/200 - Train Loss: 0.8147 - Val Loss: 0.8877\n",
      "Epoch 14/200 - Train Loss: 0.8009 - Val Loss: 0.8826\n",
      "Epoch 15/200 - Train Loss: 0.7946 - Val Loss: 0.8772\n",
      "Epoch 16/200 - Train Loss: 0.8151 - Val Loss: 0.8721\n",
      "Epoch 17/200 - Train Loss: 0.7859 - Val Loss: 0.8662\n",
      "Epoch 18/200 - Train Loss: 0.7811 - Val Loss: 0.8602\n",
      "Epoch 19/200 - Train Loss: 0.7838 - Val Loss: 0.8560\n",
      "Epoch 20/200 - Train Loss: 0.8082 - Val Loss: 0.8548\n",
      "Epoch 21/200 - Train Loss: 0.7882 - Val Loss: 0.8522\n",
      "Epoch 22/200 - Train Loss: 0.8029 - Val Loss: 0.8507\n",
      "Epoch 23/200 - Train Loss: 0.7856 - Val Loss: 0.8483\n",
      "Epoch 24/200 - Train Loss: 0.8278 - Val Loss: 0.8496\n",
      "Epoch 25/200 - Train Loss: 0.7897 - Val Loss: 0.8477\n",
      "Epoch 26/200 - Train Loss: 0.7977 - Val Loss: 0.8464\n",
      "Epoch 27/200 - Train Loss: 0.7741 - Val Loss: 0.8424\n",
      "Epoch 28/200 - Train Loss: 0.7652 - Val Loss: 0.8380\n",
      "Epoch 29/200 - Train Loss: 0.7671 - Val Loss: 0.8361\n",
      "Epoch 30/200 - Train Loss: 0.7878 - Val Loss: 0.8373\n",
      "Epoch 31/200 - Train Loss: 0.7575 - Val Loss: 0.8343\n",
      "Epoch 32/200 - Train Loss: 0.7804 - Val Loss: 0.8329\n",
      "Epoch 33/200 - Train Loss: 0.7807 - Val Loss: 0.8289\n",
      "Epoch 34/200 - Train Loss: 0.7945 - Val Loss: 0.8247\n",
      "Epoch 35/200 - Train Loss: 0.7745 - Val Loss: 0.8222\n",
      "Epoch 36/200 - Train Loss: 0.7823 - Val Loss: 0.8223\n",
      "Epoch 37/200 - Train Loss: 0.7583 - Val Loss: 0.8210\n",
      "Epoch 38/200 - Train Loss: 0.7688 - Val Loss: 0.8297\n",
      "Epoch 39/200 - Train Loss: 0.7684 - Val Loss: 0.8500\n",
      "Epoch 40/200 - Train Loss: 0.7688 - Val Loss: 0.8507\n",
      "Epoch 41/200 - Train Loss: 0.7547 - Val Loss: 0.8189\n",
      "Epoch 42/200 - Train Loss: 0.7791 - Val Loss: 0.8079\n",
      "Epoch 43/200 - Train Loss: 0.7708 - Val Loss: 0.8041\n",
      "Epoch 44/200 - Train Loss: 0.7772 - Val Loss: 0.8071\n",
      "Epoch 45/200 - Train Loss: 0.7450 - Val Loss: 0.8085\n",
      "Epoch 46/200 - Train Loss: 0.7673 - Val Loss: 0.8071\n",
      "Epoch 47/200 - Train Loss: 0.7726 - Val Loss: 0.8047\n",
      "Epoch 48/200 - Train Loss: 0.7717 - Val Loss: 0.8028\n",
      "Epoch 49/200 - Train Loss: 0.7656 - Val Loss: 0.8019\n",
      "Epoch 50/200 - Train Loss: 0.7575 - Val Loss: 0.8006\n",
      "Epoch 51/200 - Train Loss: 0.7420 - Val Loss: 0.7998\n",
      "Epoch 52/200 - Train Loss: 0.7499 - Val Loss: 0.7961\n",
      "Epoch 53/200 - Train Loss: 0.7660 - Val Loss: 0.7990\n",
      "Epoch 54/200 - Train Loss: 0.7751 - Val Loss: 0.8027\n",
      "Epoch 55/200 - Train Loss: 0.7648 - Val Loss: 0.8043\n",
      "Epoch 56/200 - Train Loss: 0.7411 - Val Loss: 0.8072\n",
      "Epoch 57/200 - Train Loss: 0.7352 - Val Loss: 0.8137\n",
      "Epoch 58/200 - Train Loss: 0.7307 - Val Loss: 0.8030\n",
      "Epoch 59/200 - Train Loss: 0.7673 - Val Loss: 0.7960\n",
      "Epoch 60/200 - Train Loss: 0.7514 - Val Loss: 0.7927\n",
      "Epoch 61/200 - Train Loss: 0.7370 - Val Loss: 0.7891\n",
      "Epoch 62/200 - Train Loss: 0.7747 - Val Loss: 0.7908\n",
      "Epoch 63/200 - Train Loss: 0.7561 - Val Loss: 0.7978\n",
      "Epoch 64/200 - Train Loss: 0.7659 - Val Loss: 0.8035\n",
      "Epoch 65/200 - Train Loss: 0.7532 - Val Loss: 0.7996\n",
      "Epoch 66/200 - Train Loss: 0.7420 - Val Loss: 0.7893\n",
      "Epoch 67/200 - Train Loss: 0.7445 - Val Loss: 0.7885\n",
      "Epoch 68/200 - Train Loss: 0.7410 - Val Loss: 0.7901\n",
      "Epoch 69/200 - Train Loss: 0.7142 - Val Loss: 0.7939\n",
      "Epoch 70/200 - Train Loss: 0.7658 - Val Loss: 0.8031\n",
      "Epoch 71/200 - Train Loss: 0.7493 - Val Loss: 0.8106\n",
      "Epoch 72/200 - Train Loss: 0.7567 - Val Loss: 0.8055\n",
      "Epoch 73/200 - Train Loss: 0.7533 - Val Loss: 0.7878\n",
      "Epoch 74/200 - Train Loss: 0.7346 - Val Loss: 0.7816\n",
      "Epoch 75/200 - Train Loss: 0.7492 - Val Loss: 0.7875\n",
      "Epoch 76/200 - Train Loss: 0.7494 - Val Loss: 0.7908\n",
      "Epoch 77/200 - Train Loss: 0.7303 - Val Loss: 0.7925\n",
      "Epoch 78/200 - Train Loss: 0.7758 - Val Loss: 0.7976\n",
      "Epoch 79/200 - Train Loss: 0.7342 - Val Loss: 0.7957\n",
      "Epoch 80/200 - Train Loss: 0.7516 - Val Loss: 0.7926\n",
      "Epoch 81/200 - Train Loss: 0.7667 - Val Loss: 0.7895\n",
      "Epoch 82/200 - Train Loss: 0.7285 - Val Loss: 0.7869\n",
      "Epoch 83/200 - Train Loss: 0.7376 - Val Loss: 0.7868\n",
      "Epoch 84/200 - Train Loss: 0.7056 - Val Loss: 0.7826\n",
      "Epoch 85/200 - Train Loss: 0.7404 - Val Loss: 0.7820\n",
      "Epoch 86/200 - Train Loss: 0.7469 - Val Loss: 0.7837\n",
      "Epoch 87/200 - Train Loss: 0.7315 - Val Loss: 0.7881\n",
      "Epoch 88/200 - Train Loss: 0.7247 - Val Loss: 0.7902\n",
      "Epoch 89/200 - Train Loss: 0.7416 - Val Loss: 0.7887\n",
      "Epoch 90/200 - Train Loss: 0.7497 - Val Loss: 0.7888\n",
      "Epoch 91/200 - Train Loss: 0.7387 - Val Loss: 0.7813\n",
      "Epoch 92/200 - Train Loss: 0.7037 - Val Loss: 0.7750\n",
      "Epoch 93/200 - Train Loss: 0.7222 - Val Loss: 0.7727\n",
      "Epoch 94/200 - Train Loss: 0.7226 - Val Loss: 0.7726\n",
      "Epoch 95/200 - Train Loss: 0.7504 - Val Loss: 0.7750\n",
      "Epoch 96/200 - Train Loss: 0.7172 - Val Loss: 0.7770\n",
      "Epoch 97/200 - Train Loss: 0.7411 - Val Loss: 0.7783\n",
      "Epoch 98/200 - Train Loss: 0.7411 - Val Loss: 0.7807\n",
      "Epoch 99/200 - Train Loss: 0.7175 - Val Loss: 0.7809\n",
      "Epoch 100/200 - Train Loss: 0.7479 - Val Loss: 0.7798\n",
      "Epoch 101/200 - Train Loss: 0.7271 - Val Loss: 0.7779\n",
      "Epoch 102/200 - Train Loss: 0.6997 - Val Loss: 0.7762\n",
      "Epoch 103/200 - Train Loss: 0.7416 - Val Loss: 0.7742\n",
      "Epoch 104/200 - Train Loss: 0.7058 - Val Loss: 0.7737\n",
      "Epoch 105/200 - Train Loss: 0.7232 - Val Loss: 0.7741\n",
      "Epoch 106/200 - Train Loss: 0.6894 - Val Loss: 0.7741\n",
      "Epoch 107/200 - Train Loss: 0.7406 - Val Loss: 0.7719\n",
      "Epoch 108/200 - Train Loss: 0.7081 - Val Loss: 0.7703\n",
      "Epoch 109/200 - Train Loss: 0.7247 - Val Loss: 0.7690\n",
      "Epoch 110/200 - Train Loss: 0.6943 - Val Loss: 0.7676\n",
      "Epoch 111/200 - Train Loss: 0.6991 - Val Loss: 0.7653\n",
      "Epoch 112/200 - Train Loss: 0.7178 - Val Loss: 0.7654\n",
      "Epoch 113/200 - Train Loss: 0.7039 - Val Loss: 0.7636\n",
      "Epoch 114/200 - Train Loss: 0.7517 - Val Loss: 0.7619\n",
      "Epoch 115/200 - Train Loss: 0.7193 - Val Loss: 0.7628\n",
      "Epoch 116/200 - Train Loss: 0.7042 - Val Loss: 0.7650\n",
      "Epoch 117/200 - Train Loss: 0.6968 - Val Loss: 0.7682\n",
      "Epoch 118/200 - Train Loss: 0.6941 - Val Loss: 0.7712\n",
      "Epoch 119/200 - Train Loss: 0.7033 - Val Loss: 0.7716\n",
      "Epoch 120/200 - Train Loss: 0.7043 - Val Loss: 0.7800\n",
      "Epoch 121/200 - Train Loss: 0.6807 - Val Loss: 0.7851\n",
      "Epoch 122/200 - Train Loss: 0.6861 - Val Loss: 0.7829\n",
      "Epoch 123/200 - Train Loss: 0.6960 - Val Loss: 0.7774\n",
      "Epoch 124/200 - Train Loss: 0.6878 - Val Loss: 0.7733\n",
      "Epoch 125/200 - Train Loss: 0.6959 - Val Loss: 0.7741\n",
      "Epoch 126/200 - Train Loss: 0.7209 - Val Loss: 0.7739\n",
      "Epoch 127/200 - Train Loss: 0.6820 - Val Loss: 0.7733\n",
      "Epoch 128/200 - Train Loss: 0.7007 - Val Loss: 0.7741\n",
      "Epoch 129/200 - Train Loss: 0.6955 - Val Loss: 0.7676\n",
      "Epoch 130/200 - Train Loss: 0.6937 - Val Loss: 0.7632\n",
      "Epoch 131/200 - Train Loss: 0.7036 - Val Loss: 0.7634\n",
      "Epoch 132/200 - Train Loss: 0.6718 - Val Loss: 0.7624\n",
      "Epoch 133/200 - Train Loss: 0.6850 - Val Loss: 0.7635\n",
      "Epoch 134/200 - Train Loss: 0.6726 - Val Loss: 0.7638\n",
      "Epoch 135/200 - Train Loss: 0.6697 - Val Loss: 0.7636\n",
      "Epoch 136/200 - Train Loss: 0.6865 - Val Loss: 0.7619\n",
      "Epoch 137/200 - Train Loss: 0.6890 - Val Loss: 0.7614\n",
      "Epoch 138/200 - Train Loss: 0.6639 - Val Loss: 0.7626\n",
      "Epoch 139/200 - Train Loss: 0.6807 - Val Loss: 0.7630\n",
      "Epoch 140/200 - Train Loss: 0.6566 - Val Loss: 0.7556\n",
      "Epoch 141/200 - Train Loss: 0.6749 - Val Loss: 0.7508\n",
      "Epoch 142/200 - Train Loss: 0.6696 - Val Loss: 0.7482\n",
      "Epoch 143/200 - Train Loss: 0.6845 - Val Loss: 0.7491\n",
      "Epoch 144/200 - Train Loss: 0.6734 - Val Loss: 0.7506\n",
      "Epoch 145/200 - Train Loss: 0.6423 - Val Loss: 0.7535\n",
      "Epoch 146/200 - Train Loss: 0.6614 - Val Loss: 0.7566\n",
      "Epoch 147/200 - Train Loss: 0.6644 - Val Loss: 0.7625\n",
      "Epoch 148/200 - Train Loss: 0.6956 - Val Loss: 0.7670\n",
      "Epoch 149/200 - Train Loss: 0.6805 - Val Loss: 0.7612\n",
      "Epoch 150/200 - Train Loss: 0.6546 - Val Loss: 0.7592\n",
      "Epoch 151/200 - Train Loss: 0.6872 - Val Loss: 0.7672\n",
      "Epoch 152/200 - Train Loss: 0.6690 - Val Loss: 0.7835\n",
      "Epoch 153/200 - Train Loss: 0.6273 - Val Loss: 0.7944\n",
      "Epoch 154/200 - Train Loss: 0.6420 - Val Loss: 0.7840\n",
      "Epoch 155/200 - Train Loss: 0.6401 - Val Loss: 0.7841\n",
      "Epoch 156/200 - Train Loss: 0.6568 - Val Loss: 0.7657\n",
      "Epoch 157/200 - Train Loss: 0.6747 - Val Loss: 0.7580\n",
      "Epoch 158/200 - Train Loss: 0.6530 - Val Loss: 0.7579\n",
      "Epoch 159/200 - Train Loss: 0.6301 - Val Loss: 0.7583\n",
      "Epoch 160/200 - Train Loss: 0.6723 - Val Loss: 0.7586\n",
      "Epoch 161/200 - Train Loss: 0.6273 - Val Loss: 0.7583\n",
      "Epoch 162/200 - Train Loss: 0.6301 - Val Loss: 0.7521\n",
      "Epoch 163/200 - Train Loss: 0.6448 - Val Loss: 0.7515\n",
      "Epoch 164/200 - Train Loss: 0.6582 - Val Loss: 0.7515\n",
      "Epoch 165/200 - Train Loss: 0.6278 - Val Loss: 0.7500\n",
      "Epoch 166/200 - Train Loss: 0.6411 - Val Loss: 0.7470\n",
      "Epoch 167/200 - Train Loss: 0.6315 - Val Loss: 0.7462\n",
      "Epoch 168/200 - Train Loss: 0.6406 - Val Loss: 0.7464\n",
      "Epoch 169/200 - Train Loss: 0.6658 - Val Loss: 0.7527\n",
      "Epoch 170/200 - Train Loss: 0.6317 - Val Loss: 0.7559\n",
      "Epoch 171/200 - Train Loss: 0.6593 - Val Loss: 0.7606\n",
      "Epoch 172/200 - Train Loss: 0.6152 - Val Loss: 0.7617\n",
      "Epoch 173/200 - Train Loss: 0.6479 - Val Loss: 0.7560\n",
      "Epoch 174/200 - Train Loss: 0.6431 - Val Loss: 0.7484\n",
      "Epoch 175/200 - Train Loss: 0.6344 - Val Loss: 0.7420\n",
      "Epoch 176/200 - Train Loss: 0.6385 - Val Loss: 0.7396\n",
      "Epoch 177/200 - Train Loss: 0.6307 - Val Loss: 0.7395\n",
      "Epoch 178/200 - Train Loss: 0.6308 - Val Loss: 0.7387\n",
      "Epoch 179/200 - Train Loss: 0.6193 - Val Loss: 0.7383\n",
      "Epoch 180/200 - Train Loss: 0.6092 - Val Loss: 0.7387\n",
      "Epoch 181/200 - Train Loss: 0.6093 - Val Loss: 0.7383\n",
      "Epoch 182/200 - Train Loss: 0.6209 - Val Loss: 0.7344\n",
      "Epoch 183/200 - Train Loss: 0.6245 - Val Loss: 0.7347\n",
      "Epoch 184/200 - Train Loss: 0.6265 - Val Loss: 0.7361\n",
      "Epoch 185/200 - Train Loss: 0.6253 - Val Loss: 0.7387\n",
      "Epoch 186/200 - Train Loss: 0.6223 - Val Loss: 0.7410\n",
      "Epoch 187/200 - Train Loss: 0.5944 - Val Loss: 0.7417\n",
      "Epoch 188/200 - Train Loss: 0.6226 - Val Loss: 0.7385\n",
      "Epoch 189/200 - Train Loss: 0.5994 - Val Loss: 0.7349\n",
      "Epoch 190/200 - Train Loss: 0.6098 - Val Loss: 0.7293\n",
      "Epoch 191/200 - Train Loss: 0.5874 - Val Loss: 0.7295\n",
      "Epoch 192/200 - Train Loss: 0.6097 - Val Loss: 0.7354\n",
      "Epoch 193/200 - Train Loss: 0.6043 - Val Loss: 0.7485\n",
      "Epoch 194/200 - Train Loss: 0.5943 - Val Loss: 0.7513\n",
      "Epoch 195/200 - Train Loss: 0.6179 - Val Loss: 0.7410\n",
      "Epoch 196/200 - Train Loss: 0.6063 - Val Loss: 0.7393\n",
      "Epoch 197/200 - Train Loss: 0.5963 - Val Loss: 0.7396\n",
      "Epoch 198/200 - Train Loss: 0.5996 - Val Loss: 0.7391\n",
      "Epoch 199/200 - Train Loss: 0.6083 - Val Loss: 0.7340\n",
      "Epoch 200/200 - Train Loss: 0.5874 - Val Loss: 0.7297\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "csv_file = open('LeakyReluTrainingData1.csv', mode='w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['Epoch', 'Train Loss', 'Val Loss'])\n",
    "\n",
    "train_loader = get_train_loader_ratio(train_dataset, full_count=16, mixed_count=0, empty_count=0)\n",
    "\n",
    "num_epochs = session_epochs[0]\n",
    "history = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode.\n",
    "    train_loss = 0.0\n",
    "    train_losses = []\n",
    "    for inputs, targets in train_loader:\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Move the data to the proper device.\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # do the training stuff\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_losses.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # Accumulate the loss for this batch.\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    result = evaluate(model, val_loader)\n",
    "    result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "    history.append(result)\n",
    "    # Compute average training loss.\n",
    "    #train_loss /= len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {result['train_loss']:.4f} - Val Loss: {result['val_loss']:.4f}\")\n",
    "    csv_writer.writerow([epoch+1, result['train_loss'], result['val_loss']])\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e1b4815",
   "metadata": {
    "id": "6e1b4815",
    "outputId": "dd4e585b-5daf-4755-897d-08f9062577d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): BottleneckResBlock(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Dropout2d(p=0.1, inplace=False)\n",
       "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'training1.ai')\n",
    "\n",
    "# load the model\n",
    "model = UNet(n_channels=1, n_classes=4)\n",
    "model.load_state_dict(torch.load('training1.ai'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5cd229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_train_loader_ratio(train_dataset, full_count=6, mixed_count=10, empty_count=0)\n",
    "\n",
    "\n",
    "csv_file = open('LeakyReluTrainingData2.csv', mode='w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['Epoch', 'Train Loss', 'Val Loss'])\n",
    "\n",
    "num_epochs = session_epochs[1]\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode.\n",
    "    train_loss = 0.0\n",
    "    train_losses = []\n",
    "    for inputs, targets in train_loader:\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Move the data to the proper device.\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # do the training stuff\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_losses.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # Accumulate the loss for this batch.\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    result = evaluate(model, val_loader)\n",
    "    result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "    history.append(result)\n",
    "    # Compute average training loss.\n",
    "    #train_loss /= len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {result['train_loss']:.4f} - Val Loss: {result['val_loss']:.4f}\")\n",
    "    csv_writer.writerow([epoch+1, result['train_loss'], result['val_loss']])\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "516af043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): BottleneckResBlock(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Dropout2d(p=0.1, inplace=False)\n",
       "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'training2.ai')\n",
    "\n",
    "# load the model\n",
    "model = UNet(n_channels=1, n_classes=4)\n",
    "model.load_state_dict(torch.load('training2.ai'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92391613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Train Loss: 0.7126 - Val Loss: 0.7296\n",
      "Epoch 2/100 - Train Loss: 0.7143 - Val Loss: 0.7290\n",
      "Epoch 3/100 - Train Loss: 0.6822 - Val Loss: 0.7288\n",
      "Epoch 4/100 - Train Loss: 0.7274 - Val Loss: 0.7290\n",
      "Epoch 5/100 - Train Loss: 0.7358 - Val Loss: 0.7288\n",
      "Epoch 6/100 - Train Loss: 0.7069 - Val Loss: 0.7291\n",
      "Epoch 7/100 - Train Loss: 0.7178 - Val Loss: 0.7293\n",
      "Epoch 8/100 - Train Loss: 0.7329 - Val Loss: 0.7300\n",
      "Epoch 9/100 - Train Loss: 0.7114 - Val Loss: 0.7299\n",
      "Epoch 10/100 - Train Loss: 0.7204 - Val Loss: 0.7296\n",
      "Epoch 11/100 - Train Loss: 0.7187 - Val Loss: 0.7297\n",
      "Epoch 12/100 - Train Loss: 0.7297 - Val Loss: 0.7301\n",
      "Epoch 13/100 - Train Loss: 0.7271 - Val Loss: 0.7300\n",
      "Epoch 14/100 - Train Loss: 0.7190 - Val Loss: 0.7301\n",
      "Epoch 15/100 - Train Loss: 0.7321 - Val Loss: 0.7299\n",
      "Epoch 16/100 - Train Loss: 0.7345 - Val Loss: 0.7303\n",
      "Epoch 17/100 - Train Loss: 0.7291 - Val Loss: 0.7308\n",
      "Epoch 18/100 - Train Loss: 0.7141 - Val Loss: 0.7308\n",
      "Epoch 19/100 - Train Loss: 0.7427 - Val Loss: 0.7314\n",
      "Epoch 20/100 - Train Loss: 0.7108 - Val Loss: 0.7315\n",
      "Epoch 21/100 - Train Loss: 0.7285 - Val Loss: 0.7319\n",
      "Epoch 22/100 - Train Loss: 0.7132 - Val Loss: 0.7317\n",
      "Epoch 23/100 - Train Loss: 0.7277 - Val Loss: 0.7312\n",
      "Epoch 24/100 - Train Loss: 0.6975 - Val Loss: 0.7309\n",
      "Epoch 25/100 - Train Loss: 0.7288 - Val Loss: 0.7310\n",
      "Epoch 26/100 - Train Loss: 0.7426 - Val Loss: 0.7314\n",
      "Epoch 27/100 - Train Loss: 0.7249 - Val Loss: 0.7311\n",
      "Epoch 28/100 - Train Loss: 0.7409 - Val Loss: 0.7308\n",
      "Epoch 29/100 - Train Loss: 0.7326 - Val Loss: 0.7311\n",
      "Epoch 30/100 - Train Loss: 0.7334 - Val Loss: 0.7313\n",
      "Epoch 31/100 - Train Loss: 0.7374 - Val Loss: 0.7309\n",
      "Epoch 32/100 - Train Loss: 0.6893 - Val Loss: 0.7300\n",
      "Epoch 33/100 - Train Loss: 0.7203 - Val Loss: 0.7307\n",
      "Epoch 34/100 - Train Loss: 0.7283 - Val Loss: 0.7319\n",
      "Epoch 35/100 - Train Loss: 0.7391 - Val Loss: 0.7321\n",
      "Epoch 36/100 - Train Loss: 0.7343 - Val Loss: 0.7321\n",
      "Epoch 37/100 - Train Loss: 0.7261 - Val Loss: 0.7327\n",
      "Epoch 38/100 - Train Loss: 0.7146 - Val Loss: 0.7328\n",
      "Epoch 39/100 - Train Loss: 0.7230 - Val Loss: 0.7333\n",
      "Epoch 40/100 - Train Loss: 0.7338 - Val Loss: 0.7330\n",
      "Epoch 41/100 - Train Loss: 0.7367 - Val Loss: 0.7338\n",
      "Epoch 42/100 - Train Loss: 0.7204 - Val Loss: 0.7338\n",
      "Epoch 43/100 - Train Loss: 0.7068 - Val Loss: 0.7332\n",
      "Epoch 44/100 - Train Loss: 0.7063 - Val Loss: 0.7327\n",
      "Epoch 45/100 - Train Loss: 0.7250 - Val Loss: 0.7326\n",
      "Epoch 46/100 - Train Loss: 0.7162 - Val Loss: 0.7317\n",
      "Epoch 47/100 - Train Loss: 0.7233 - Val Loss: 0.7316\n",
      "Epoch 48/100 - Train Loss: 0.7221 - Val Loss: 0.7308\n",
      "Epoch 49/100 - Train Loss: 0.7001 - Val Loss: 0.7301\n",
      "Epoch 50/100 - Train Loss: 0.7271 - Val Loss: 0.7305\n",
      "Epoch 51/100 - Train Loss: 0.7240 - Val Loss: 0.7297\n",
      "Epoch 52/100 - Train Loss: 0.7142 - Val Loss: 0.7300\n",
      "Epoch 53/100 - Train Loss: 0.6908 - Val Loss: 0.7294\n",
      "Epoch 54/100 - Train Loss: 0.6974 - Val Loss: 0.7299\n",
      "Epoch 55/100 - Train Loss: 0.7274 - Val Loss: 0.7311\n",
      "Epoch 56/100 - Train Loss: 0.7328 - Val Loss: 0.7320\n",
      "Epoch 57/100 - Train Loss: 0.7293 - Val Loss: 0.7325\n",
      "Epoch 58/100 - Train Loss: 0.7258 - Val Loss: 0.7324\n",
      "Epoch 59/100 - Train Loss: 0.7329 - Val Loss: 0.7329\n",
      "Epoch 60/100 - Train Loss: 0.7145 - Val Loss: 0.7332\n",
      "Epoch 61/100 - Train Loss: 0.7090 - Val Loss: 0.7328\n",
      "Epoch 62/100 - Train Loss: 0.7487 - Val Loss: 0.7324\n",
      "Epoch 63/100 - Train Loss: 0.7362 - Val Loss: 0.7322\n",
      "Epoch 64/100 - Train Loss: 0.7263 - Val Loss: 0.7325\n",
      "Epoch 65/100 - Train Loss: 0.7136 - Val Loss: 0.7327\n",
      "Epoch 66/100 - Train Loss: 0.7059 - Val Loss: 0.7325\n",
      "Epoch 67/100 - Train Loss: 0.7320 - Val Loss: 0.7316\n",
      "Epoch 68/100 - Train Loss: 0.7167 - Val Loss: 0.7316\n",
      "Epoch 69/100 - Train Loss: 0.7423 - Val Loss: 0.7321\n",
      "Epoch 70/100 - Train Loss: 0.7263 - Val Loss: 0.7322\n",
      "Epoch 71/100 - Train Loss: 0.7173 - Val Loss: 0.7308\n",
      "Epoch 72/100 - Train Loss: 0.7425 - Val Loss: 0.7318\n",
      "Epoch 73/100 - Train Loss: 0.7184 - Val Loss: 0.7312\n",
      "Epoch 74/100 - Train Loss: 0.6978 - Val Loss: 0.7303\n",
      "Epoch 75/100 - Train Loss: 0.6987 - Val Loss: 0.7296\n",
      "Epoch 76/100 - Train Loss: 0.7404 - Val Loss: 0.7304\n",
      "Epoch 77/100 - Train Loss: 0.7201 - Val Loss: 0.7308\n",
      "Epoch 78/100 - Train Loss: 0.7332 - Val Loss: 0.7312\n",
      "Epoch 79/100 - Train Loss: 0.7283 - Val Loss: 0.7310\n",
      "Epoch 80/100 - Train Loss: 0.7201 - Val Loss: 0.7312\n",
      "Epoch 81/100 - Train Loss: 0.7299 - Val Loss: 0.7313\n",
      "Epoch 82/100 - Train Loss: 0.7168 - Val Loss: 0.7315\n",
      "Epoch 83/100 - Train Loss: 0.7106 - Val Loss: 0.7311\n",
      "Epoch 84/100 - Train Loss: 0.7315 - Val Loss: 0.7310\n",
      "Epoch 85/100 - Train Loss: 0.7531 - Val Loss: 0.7320\n",
      "Epoch 86/100 - Train Loss: 0.7127 - Val Loss: 0.7315\n",
      "Epoch 87/100 - Train Loss: 0.7343 - Val Loss: 0.7312\n",
      "Epoch 88/100 - Train Loss: 0.7231 - Val Loss: 0.7324\n",
      "Epoch 89/100 - Train Loss: 0.7054 - Val Loss: 0.7319\n",
      "Epoch 90/100 - Train Loss: 0.7071 - Val Loss: 0.7319\n",
      "Epoch 91/100 - Train Loss: 0.7084 - Val Loss: 0.7319\n",
      "Epoch 92/100 - Train Loss: 0.7175 - Val Loss: 0.7320\n",
      "Epoch 93/100 - Train Loss: 0.7372 - Val Loss: 0.7322\n",
      "Epoch 94/100 - Train Loss: 0.7348 - Val Loss: 0.7324\n",
      "Epoch 95/100 - Train Loss: 0.7143 - Val Loss: 0.7320\n",
      "Epoch 96/100 - Train Loss: 0.7312 - Val Loss: 0.7323\n",
      "Epoch 97/100 - Train Loss: 0.7140 - Val Loss: 0.7317\n",
      "Epoch 98/100 - Train Loss: 0.7082 - Val Loss: 0.7309\n",
      "Epoch 99/100 - Train Loss: 0.7377 - Val Loss: 0.7305\n",
      "Epoch 100/100 - Train Loss: 0.7292 - Val Loss: 0.7302\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_train_loader_ratio(train_dataset, full_count=2, mixed_count=6, empty_count=8)\n",
    "num_epochs = session_epochs[2]\n",
<<<<<<< Updated upstream
    "csv_file = open('./LeakyReLu/LeakyReluTrainingData3.csv', mode='w', newline='')\n",
=======
    "csv_file = open('LeakyReluTrainingData3.csv', mode='w', newline='')\n",
>>>>>>> Stashed changes
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['Epoch', 'Train Loss', 'Val Loss'])\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode.\n",
    "    train_loss = 0.0\n",
    "    train_losses = []\n",
    "    for inputs, targets in train_loader:\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Move the data to the proper device.\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # do the training stuff\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_losses.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # Accumulate the loss for this batch.\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    result = evaluate(model, val_loader)\n",
    "    result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "    history.append(result)\n",
    "    # Compute average training loss.\n",
    "    #train_loss /= len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {result['train_loss']:.4f} - Val Loss: {result['val_loss']:.4f}\")\n",
    "    csv_writer.writerow([epoch+1, result['train_loss'], result['val_loss']])\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f7e3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'training3.ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb044768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): BottleneckResBlock(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): Dropout2d(p=0.1, inplace=False)\n",
       "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# load the model\n",
    "model = UNet(n_channels=1, n_classes=4)\n",
    "model.load_state_dict(torch.load('training3.ai'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b491f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed751f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66ea5d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateIoU(gtMask, predMask):\n",
    "    # Calculate the true positives,\n",
    "    # false positives, and false negatives\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    for i in range(len(gtMask)):\n",
    "        for j in range(len(gtMask[0])):\n",
    "            if gtMask[i][j] == 1 and predMask[i][j] == 1:\n",
    "                tp += 1\n",
    "            elif gtMask[i][j] == 0 and predMask[i][j] == 1:\n",
    "                fp += 1\n",
    "            elif gtMask[i][j] == 1 and predMask[i][j] == 0:\n",
    "                fn += 1\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = tp / (tp + fp + fn + 1e-6)  # Adding a small value to avoid division by zero\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28850c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on the test set\n",
    "def predict(model, test_loader):\n",
    "    iou = []\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            outputs = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "        # Calculate IoU for each class\n",
    "        for i in range(len(outputs)):\n",
    "            pred_mask = outputs[i]\n",
    "            gt_mask = targets[i].cpu().numpy()\n",
    "            iou.append(calculateIoU(gt_mask, pred_mask))\n",
    "    #Average IoU across all classes\n",
    "    avg_iou = sum(iou) / len(iou)\n",
    "    return avg_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93f8f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1a24938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average IoU: 0.18396152191852777\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Average IoU:\", iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8add78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_with_mask(image: torch.tensor, mask: np.ndarray, alpha: float = 0.5):\n",
    "    \"\"\"\n",
    "    Display a grayscale image with a binary mask overlaid.\n",
    "\n",
    "    Parameters:\n",
    "    - image: 2D tensor for a scan\n",
    "    - mask:  2D numpy array of same shape with binary values (0 or 1).\n",
    "    - alpha: float transparency for mask overlay.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.imshow(mask, alpha=alpha)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04c6f1f0",
   "metadata": {
    "id": "04c6f1f0",
    "outputId": "58b85953-cc11-4edd-f84e-6ed5024f9417"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'case133_day25_slice_0049'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# errors with: case133_day25_slice_0049, All of day 77\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X, y = \u001b[43mmrid\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcase133_day25_slice_0049\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(mrid))\n\u001b[32m      5\u001b[39m display_image_with_mask(X.squeeze(), y)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mMRIData.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(idx) == \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mslices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m.features(device=\u001b[38;5;28mself\u001b[39m.device), \u001b[38;5;28mself\u001b[39m.slices[idx].mask.astype(np.int64)\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.slice_index[idx].features(device=\u001b[38;5;28mself\u001b[39m.device), \u001b[38;5;28mself\u001b[39m.slice_index[idx].mask.astype(np.int64)\n",
      "\u001b[31mKeyError\u001b[39m: 'case133_day25_slice_0049'"
     ]
    }
   ],
   "source": [
    "# errors with: case133_day25_slice_0049, All of day 77\n",
    "X, y = mrid[\"case133_day25_slice_0049\"]\n",
    "print(len(mrid))\n",
    "\n",
    "display_image_with_mask(X.squeeze(), y)\n",
    "\n",
    "X_pred = X.unsqueeze(0).to(device)\n",
    "y_pred = model(X_pred)\n",
    "\n",
    "y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "y_print = y_pred.detach().cpu().numpy()\n",
    "display_image_with_mask(X.squeeze(), y_print.squeeze())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
